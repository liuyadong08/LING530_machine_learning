{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3822523a",
   "metadata": {},
   "source": [
    "# HW1: Linear classifiers\n",
    "    \n",
    "In this homework assignment, we'll compare two linear classifiers: logistic regression and perceptron on the task of language identification. \n",
    "\n",
    "Before you start, rename the notebook to HW2_linear_classifiers_firstname.ipynb. E.g. HW2_linear_classifiers_miikka.ipynb.\n",
    "\n",
    "Our tasks include:\n",
    "\n",
    "1. Reading training, development and test data\n",
    "1. Implementing a feature extraction function for language identification\n",
    "1. Implementing a baseline majority classifier\n",
    "1. Training and fine-tuning logistic regression and perceptron classifiers using Sklearn.\n",
    "1. Evaluation of classification performance including a significance test.\n",
    "1. Figuring out top features for both classifiers. \n",
    "1. Writing short report on your findings.\n",
    "\n",
    "Grading criteria for code:\n",
    "\n",
    "* Readability of code\n",
    "* Correctness of code and solution\n",
    "* Appropriate code commenting\n",
    "* Your code should be reasonably efficient. No need to optimize too much but (apart from fine-tuning code) it should be possible to run the entire notebook in 30 minutes.\n",
    "\n",
    "Grading criteria for the half-page report (in assignment 7. Evaluation):\n",
    "\n",
    "* Clear explanation of what you did\n",
    "* Clear explanation of your observations concerning the output of the classifier.\n",
    "* You need to include answers to the questions posed in assignment 1-6.\n",
    "\n",
    "The deadline for this assignment is Sunday November 5 at 23:59 PT. Please upload your notebook to Canvas or email it to Miikka (msilfver@mail.ubc.ca). No need to include the datasets.\n",
    "\n",
    "## 1. Reading training, development and test data (5 points)\n",
    "\n",
    "You task is to distinguish between short sentence fragments in English, French, German and Swedish. You will get three data files for this assignment:\n",
    "\n",
    "* `lang.train.tsv` for training your model\n",
    "* `lang.dev.tsv` for fine-tuning model parameters\n",
    "* `lang.test.tsv` for final testing of your models including significance tests\n",
    "\n",
    "The data in all files has the same format. Two tab-separated columns: (1) the sentence fragment, (2) the language tag (de for German, en for English, fr for French, sv for Swedish):\n",
    "\n",
    "```\n",
    "text                    language\n",
    "même prix je me         fr\n",
    "je préfère ignorer son  fr\n",
    "die mediation           de\n",
    "two                     en\n",
    "to end                  en\n",
    "```\n",
    "\n",
    "You should read these files into three Pandas data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "272bed0e-c029-4ce1-94c7-4eaf8eb85034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, roc_curve, RocCurveDisplay\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "import numpy as np\n",
    "from scipy.stats import wilcoxon, ttest_rel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "268a4c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            text language\n",
      "0                même prix je me       fr\n",
      "1         je préfère ignorer son       fr\n",
      "2                  die mediation       de\n",
      "3                            two       en\n",
      "4                         to end       en\n",
      "...                          ...      ...\n",
      "4813               et morte le 2       fr\n",
      "4814   il comptait 249 habitants       fr\n",
      "4815          links zu von sears       de\n",
      "4816  clemens gerth zirka kunden       de\n",
      "4817         die abschaffung der       de\n",
      "\n",
      "[4818 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# loading datasets\n",
    "train = pd.read_csv(\"lang.train.tsv\",  sep = \"\\t\")\n",
    "dev = pd.read_csv(\"lang.dev.tsv\", sep = \"\\t\")\n",
    "test = pd.read_csv(\"lang.test.tsv\", sep = \"\\t\")\n",
    "\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9618153e",
   "metadata": {},
   "source": [
    "## 2. Feature extraction (20 points)\n",
    "\n",
    "You are allowed to use any approach you like for feature extraction. One idea is to use [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) but you can also extract your features manually and apply [DictVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html#sklearn.feature_extraction.DictVectorizer.get_feature_names_out) (note, that the class names are links to the sklearn documentation)\n",
    "\n",
    "If you end up using CountVectorizer, note that it by default only extracts **word** n-grams. While this can give you reasonable performance, it probably isn't the best approach because words like \"abschaffung\" are rare and word-based features are unlikely to generalize well to test data. Instead, it might be a better idea to extract **substrings** of the sentence fragment like \"absch\" which can generalize far better. To this end, you might want to take a look at the parameter `analyzer` in the CountVectorizer class.\n",
    "\n",
    "Even though most words are rare, there are words like \"a\", \"the\", \"is\" in English and \"le\", \"la\" and \"est\" in French which can be good and frequent features. You might want to include some of these even though they might, at least partly, be covered by your character n-grams.\n",
    "\n",
    "You have great freedom to extract features any way you like. You don't need to limit yourself to the predefined sklearn features. You can even use external resources like dictionaries for this task if you want. For example, the [Unimorph](https://unimorph.github.io/) project provides huge lists of inflected word forms for all of our target languages. Checking how many of the words in the sentence fragment are present in the English, French, German or Swedish word list could be a nice feature.\n",
    "\n",
    "Note, that you will fine-tune your feature set in assignment 4. For example, you might adjust the size of the character n-grams which are included as features. For now, use reasonable guesses and revisit the question when you get to assignment 4.  \n",
    "\n",
    "Store your features in the arrays `train_X`, `dev_X` and `test_X`.\n",
    "\n",
    "In your report (question 7), you should describe your feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9184b154-218b-40f8-ac43-7a2cc1cc9403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             stem       inflected           form\n",
      "0      Washington      Washington  N;NOM;NEUT;SG\n",
      "1      Washington     Washingtons  N;GEN;NEUT;SG\n",
      "2      Washington      Washington  N;DAT;NEUT;SG\n",
      "3      Washington      Washington  N;ACC;NEUT;SG\n",
      "4  Hirschhornsalz  Hirschhornsalz  N;NOM;NEUT;SG\n"
     ]
    }
   ],
   "source": [
    "# get inflected word forms for each language\n",
    "en_url = 'https://raw.githubusercontent.com/unimorph/eng/master/eng'\n",
    "en_df = pd.read_csv(en_url,header = None, names = [\"stem\", \"inflected\", \"form\"], sep = \"\\t\")\n",
    "fr_url = 'https://raw.githubusercontent.com/unimorph/fra/master/fra'\n",
    "fr_df = pd.read_csv(fr_url,header = None, names = [\"stem\", \"inflected\", \"form\"], sep = \"\\t\")\n",
    "de_url = 'https://raw.githubusercontent.com/unimorph/deu/master/deu'\n",
    "de_df = pd.read_csv(de_url,header = None, names = [\"stem\", \"inflected\", \"form\"], sep = \"\\t\")\n",
    "sv_url = 'https://raw.githubusercontent.com/unimorph/swe/master/swe'\n",
    "sv_df = pd.read_csv(sv_url,header = None, names = [\"stem\", \"inflected\", \"form\"], sep = \"\\t\")\n",
    "\n",
    "print(de_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd133bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_ngram(text, maxn, maxlen):\n",
    "    \"\"\"get n-grams out of a sentence fragment\"\"\"\n",
    "    ngram = []\n",
    "    for i in range(0, len(text) + 1 - maxn):\n",
    "        for j in range(i + maxn, min(i + maxn + 1, len(text) + 1)):\n",
    "            ngram.append(text[i:j])\n",
    "    return ngram\n",
    "def feature_extraction(data):\n",
    "    \"\"\"extract features from text and gather langauge tags\"\"\"\n",
    "    data_features = []\n",
    "    for text in data.text:\n",
    "        features = {\n",
    "            \"char_bigram\" : char_ngram(text, 2, 50), # character bigram\n",
    "            \"char_trigram\" : char_ngram(text, 3, 50), # character trigram\n",
    "            \"en_word_no\": len([word for word in text.split(\" \") if word in en_df.inflected.iloc[1]]), # number of English inflected word\n",
    "            \"fr_word_no\": len([word for word in text.split(\" \") if word in fr_df.inflected.iloc[1]]), # number of French inflected word\n",
    "            \"de_word_no\": len([word for word in text.split(\" \") if word in de_df.inflected.iloc[1]]), # number of German inflected word\n",
    "            \"sv_word_no\": len([word for word in text.split(\" \") if word in sv_df.inflected.iloc[1]]), # number of Swedish inflected word\n",
    "        }\n",
    "        if len(list(set(text.split(\" \")) & set([\"a\", \"the\", \"is\", \"are\", \"was\", \"were\"])))>0: # existance of English common word\n",
    "            features[\"EN_common_word\"] = \"YES\"\n",
    "        if len(list(set(text.split(\" \")) & set([\"un\", \"une\", \"le\", \"la\", \"est\"])))>0: # existance of French common word\n",
    "            features[\"FR_common_word\"] = \"YES\"\n",
    "        if len(list(set(text.split(\" \")) & set([\"ein\", \"eine\", \"die\", \"der\", \"ist\"])))>0: # existance of French common word\n",
    "            features[\"DE_common_word\"] = \"YES\" \n",
    "        if len(list(set(text.split(\" \")) & set([\"en\", \"ett\", \"är\", \"var\", \"det\"])))>0: # existance of Swedish common word\n",
    "            features[\"SV_common_word\"] = \"YES\"\n",
    "            \n",
    "        data_features.append(features)\n",
    "    return data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac2b8605-4703-4be7-b649-097a5a2bd669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features from train, dev, and test dataset.\n",
    "train_features = feature_extraction(train)\n",
    "dev_features= feature_extraction(dev)\n",
    "test_features = feature_extraction(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d9c5331-bb57-450b-a01c-570ccd2dfb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a DictVectorizer and vectorize features in train, dev, and test.\n",
    "feature_encoder = DictVectorizer()\n",
    "\n",
    "train_X = feature_encoder.fit_transform(train_features)\n",
    "dev_X = feature_encoder.transform(dev_features)\n",
    "test_X = feature_encoder.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d8d88d",
   "metadata": {},
   "source": [
    "## 3. Baseline (5 points)\n",
    "\n",
    "You should then encode your labels into index numbers using [sklearn.preprocessing.LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html). Store your labels in `train_y`, `dev_y` and `test_y`.\n",
    "\n",
    "Then train a baseline majority classifier using [DummyClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html). Check the macro averaged f-score on the development set. It should be pretty low (around 10%). \n",
    "\n",
    "In your report (question 7), you should answer the following questions:\n",
    "* Why do you think the baseline performance is low?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6907107c-bf34-4b66-b818-10fc83f7ab8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de' 'en' 'fr' 'sv']\n"
     ]
    }
   ],
   "source": [
    "# encode labels in train, dev, and test into index numbers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(train.language)\n",
    "\n",
    "train_y = label_encoder.transform(train.language)\n",
    "dev_y = label_encoder.transform(dev.language)\n",
    "test_y = label_encoder.transform(test.language)\n",
    "\n",
    "\n",
    "print(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ccb9bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline F score: 0.09863307424283034\n"
     ]
    }
   ],
   "source": [
    "# Train a Dummyclassifier and check its performance.\n",
    "baseline = DummyClassifier(strategy=\"most_frequent\")\n",
    "baseline.fit(train_X, train_y)\n",
    "\n",
    "sys_dev_y = baseline.predict(dev_X)\n",
    "print(f\"baseline F score: {f1_score(dev_y, sys_dev_y, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10180465-fda6-4ee8-bf82-595669490ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset label count: Counter({2: 1241, 0: 1232, 1: 1228, 3: 1117})\n",
      "development dataset label count: Counter({0: 783, 1: 740, 3: 736, 2: 736})\n"
     ]
    }
   ],
   "source": [
    "print(f\"training dataset label count: {Counter(train_y)}\")\n",
    "print(f\"development dataset label count: {Counter(dev_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636b81d9",
   "metadata": {},
   "source": [
    "## 4. Training and fine-tuning classifiers (20 points)\n",
    "\n",
    "Next, you should train two models using sklearn: \n",
    "\n",
    "1. A [perceptron](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html) classifier \n",
    "2. A [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html) model. \n",
    "\n",
    "Start by training these with default parameters and check the performance (macro averaged f-score). You should be able to get **far** better performance than the baseline. Perhaps even close to or above 90% but this depends on your feature extraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d872c41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron F score: 0.9073867420011236\n"
     ]
    }
   ],
   "source": [
    "# train a perceptron classifier and check its performance\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(train_X, train_y)\n",
    "pcpt_sys_dev_y = perceptron.predict(dev_X)\n",
    "print(f\"Perceptron F score: {f1_score(dev_y, pcpt_sys_dev_y, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97921839-67c8-4fc9-8477-09a67f3140d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression F score: 0.9112870076652817\n"
     ]
    }
   ],
   "source": [
    "# train a logistic regression classifier and check its performance\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_X, train_y)\n",
    "lr_sys_dev_y = lr.predict(dev_X)\n",
    "print(f\"Logistic regression F score: {f1_score(dev_y, lr_sys_dev_y, average='macro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aa383c",
   "metadata": {},
   "source": [
    "To help you tune the feature extraction process, you should print a list of the development examples which are incorrectly classified by your current models. Also print the gold standard and predicted language. By examining this list, you might be able to identify additional helpful features, or at least understand why your classifier is confused. \n",
    "\n",
    "**HINT:** the `predict()` function will give you an index number instead of an actual language tag like \"en\". Use the `classes_` member of your label encoder to transform the index number into a language tag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5771f4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sv</th>\n",
       "      <th>en</th>\n",
       "      <th>fr</th>\n",
       "      <th>de</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(jenna marbles, en)</td>\n",
       "      <td>(hofheim, fr)</td>\n",
       "      <td>(semaine de, en)</td>\n",
       "      <td>(gendarmerie vont, fr)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(results, en)</td>\n",
       "      <td>(actives, fr)</td>\n",
       "      <td>(madame tussauds, en)</td>\n",
       "      <td>(sovereign people, en)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(cukor et, fr)</td>\n",
       "      <td>(wissen was, de)</td>\n",
       "      <td>(more details, en)</td>\n",
       "      <td>(comprimer, fr)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(hören war doch, de)</td>\n",
       "      <td>(1985, sv)</td>\n",
       "      <td>(divx, de)</td>\n",
       "      <td>(die sooner when, en)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(nom de villebetmer et, fr)</td>\n",
       "      <td>(1905, sv)</td>\n",
       "      <td>(chet clem, en)</td>\n",
       "      <td>(del 2 59, sv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(sochi russia, en)</td>\n",
       "      <td>(lassen, de)</td>\n",
       "      <td>(zirka 20 euro, de)</td>\n",
       "      <td>(90 minutes, fr)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(as president, en)</td>\n",
       "      <td>(sa population, fr)</td>\n",
       "      <td>(irrelevant, en)</td>\n",
       "      <td>(dem, sv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(hinter axero, de)</td>\n",
       "      <td>(expeditioner valbyråer, sv)</td>\n",
       "      <td>(liquid, en)</td>\n",
       "      <td>(att ge de, sv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(lv stuff, en)</td>\n",
       "      <td>(weg ins in, de)</td>\n",
       "      <td>(480 pixeln, de)</td>\n",
       "      <td>(church, en)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(300 32, de)</td>\n",
       "      <td>(576, fr)</td>\n",
       "      <td>(balans, sv)</td>\n",
       "      <td>(comme nan goldin printemps, fr)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(giovanni bellini 1505, en)</td>\n",
       "      <td>(ingås, sv)</td>\n",
       "      <td>(voice stammt den, de)</td>\n",
       "      <td>(neutraliteten, sv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(statt dessen, de)</td>\n",
       "      <td>(ha, sv)</td>\n",
       "      <td>(intressant, sv)</td>\n",
       "      <td>(15 november, sv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(postbank easytrade per internet, de)</td>\n",
       "      <td>(bromsar, sv)</td>\n",
       "      <td>(video miharris, en)</td>\n",
       "      <td>(volunteers and soldiers of, en)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(1971, fr)</td>\n",
       "      <td>(marcus andronicus annonce, fr)</td>\n",
       "      <td>(camp councillor, en)</td>\n",
       "      <td>(states until, en)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(varvara yakovleva à titre, fr)</td>\n",
       "      <td>(tid, sv)</td>\n",
       "      <td>(quite a problem, en)</td>\n",
       "      <td>(ges inte, sv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(poet, en)</td>\n",
       "      <td>(diskussion hat, de)</td>\n",
       "      <td>(priser, sv)</td>\n",
       "      <td>(en 2005, fr)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(rock reggae pop, fr)</td>\n",
       "      <td>(aigu clair, fr)</td>\n",
       "      <td>(prozess durch alle, de)</td>\n",
       "      <td>(mittlinje kan, sv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(it jenna mcmasters, en)</td>\n",
       "      <td>(fusion mit time, de)</td>\n",
       "      <td>(purposes, en)</td>\n",
       "      <td>(zuckerberg, en)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(drupa, de)</td>\n",
       "      <td>(kungsholmens byalag, sv)</td>\n",
       "      <td>(term plans, en)</td>\n",
       "      <td>(statens naturvårdsverk, sv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(davantage, fr)</td>\n",
       "      <td>(vuxit fram, sv)</td>\n",
       "      <td>(höchst dubios sagte, de)</td>\n",
       "      <td>(jag inte, sv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(i at, en)</td>\n",
       "      <td>(syn, sv)</td>\n",
       "      <td>(patrick gordon, en)</td>\n",
       "      <td>(gymnasiestudier, sv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(fertile, fr)</td>\n",
       "      <td>(system av, sv)</td>\n",
       "      <td>(1994 6, en)</td>\n",
       "      <td>(adverb auxiliary verb main, en)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(telekom kappt, de)</td>\n",
       "      <td>(4 aggregat, sv)</td>\n",
       "      <td>(portale, de)</td>\n",
       "      <td>(limb geometry, en)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(anderson, en)</td>\n",
       "      <td>(erst in, de)</td>\n",
       "      <td>(anime fantasy and, en)</td>\n",
       "      <td>(1856 macnab fut, fr)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(und edgar bronfman, de)</td>\n",
       "      <td>(kritik an, de)</td>\n",
       "      <td>(its pressure, en)</td>\n",
       "      <td>(kuvert, sv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(bild, de)</td>\n",
       "      <td>(dem meldet the, de)</td>\n",
       "      <td>(potential employers, en)</td>\n",
       "      <td>(kommissionen, sv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(de hattushili i, fr)</td>\n",
       "      <td>(ljus, sv)</td>\n",
       "      <td>(silicon valley, de)</td>\n",
       "      <td>(state commitment, en)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(toratane hara nobutaka, fr)</td>\n",
       "      <td>(se bat, fr)</td>\n",
       "      <td>(your favorite question, en)</td>\n",
       "      <td>(big ben, en)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(pete, en)</td>\n",
       "      <td>(m² elastic, fr)</td>\n",
       "      <td>(formal equivalence, en)</td>\n",
       "      <td>(bills in, en)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(lara fabian, fr)</td>\n",
       "      <td>(speed bei, de)</td>\n",
       "      <td>(alternative courses delivery, en)</td>\n",
       "      <td>(fadern makten, sv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(et de utilisation, fr)</td>\n",
       "      <td>(hästfordon, sv)</td>\n",
       "      <td>(by complementary misfortune, en)</td>\n",
       "      <td>(will be able, en)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(sony distribuera en dvd, fr)</td>\n",
       "      <td>(nu, sv)</td>\n",
       "      <td>(primacom, de)</td>\n",
       "      <td>(michael smith writes, en)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(internet explorer 6, en)</td>\n",
       "      <td>(syn, sv)</td>\n",
       "      <td>(je nach, de)</td>\n",
       "      <td>(innerst inne inte att, sv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(doppelter kapazität, de)</td>\n",
       "      <td>(1976 american association, fr)</td>\n",
       "      <td>(bit ethnocentric, en)</td>\n",
       "      <td>(javafx mobile bien, fr)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(i felt angry, en)</td>\n",
       "      <td>(2011, fr)</td>\n",
       "      <td>(large enclosure under conditions, en)</td>\n",
       "      <td>(center and stuff, en)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(den rosa riesen, de)</td>\n",
       "      <td>(sagt, sv)</td>\n",
       "      <td>(trouble, en)</td>\n",
       "      <td>(schweiz ch västtyskland d, sv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(behandelt, de)</td>\n",
       "      <td>(nedan, sv)</td>\n",
       "      <td>(maj 1970, sv)</td>\n",
       "      <td>(eugene nida, en)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(barn, en)</td>\n",
       "      <td>(thèse ou, fr)</td>\n",
       "      <td>(markfaunan, sv)</td>\n",
       "      <td>(independent, en)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(prerogative, en)</td>\n",
       "      <td>(invalides a, fr)</td>\n",
       "      <td>(alla departement, sv)</td>\n",
       "      <td>(christian rosencreutz, en)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(tarife bestätigt, de)</td>\n",
       "      <td>(group, de)</td>\n",
       "      <td>(jacques payer am, de)</td>\n",
       "      <td>(och inte mindre än, sv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(50 mark sind, de)</td>\n",
       "      <td>(irlande, fr)</td>\n",
       "      <td>(ende mai, de)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>(belle, en)</td>\n",
       "      <td>(pro domain, de)</td>\n",
       "      <td>(des aims, de)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>(still, en)</td>\n",
       "      <td>(royal servi, fr)</td>\n",
       "      <td>(his partner chris cardenas, en)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>(namen travelstar, de)</td>\n",
       "      <td>(the dream produite par, fr)</td>\n",
       "      <td>(less legitimate, en)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>(sont dda ddha nna, fr)</td>\n",
       "      <td>(18 juin 2010, fr)</td>\n",
       "      <td>(opposite her, en)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>(partnern, de)</td>\n",
       "      <td>(mesure m, fr)</td>\n",
       "      <td>(nun alles, de)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>(of ethnocentrism or evaluating, en)</td>\n",
       "      <td>(piston, fr)</td>\n",
       "      <td>(comdirect muss sparen, de)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>(anhörung in brüssel, de)</td>\n",
       "      <td>(hit från, sv)</td>\n",
       "      <td>(sufficiently clear nor sufficiently, en)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>None</td>\n",
       "      <td>(um, de)</td>\n",
       "      <td>(es ende letzten jahres, de)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>None</td>\n",
       "      <td>(edouard guillaud sur, fr)</td>\n",
       "      <td>(nu ett, sv)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>None</td>\n",
       "      <td>(ferroviaire, fr)</td>\n",
       "      <td>(a charitable capacity, en)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>None</td>\n",
       "      <td>(jones, fr)</td>\n",
       "      <td>(idea produces some puzzles, en)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>None</td>\n",
       "      <td>(bowl, fr)</td>\n",
       "      <td>(plus, de)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>None</td>\n",
       "      <td>(5 boeing 787, fr)</td>\n",
       "      <td>(siméon poisson reviewed galois, en)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>None</td>\n",
       "      <td>(inom eec, sv)</td>\n",
       "      <td>(talkline plant im, de)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>None</td>\n",
       "      <td>(frère philippe, fr)</td>\n",
       "      <td>(aggression hos lämmel, sv)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>None</td>\n",
       "      <td>(sears, de)</td>\n",
       "      <td>(equivalence, en)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>None</td>\n",
       "      <td>(men ofta, sv)</td>\n",
       "      <td>(1967 del 1 sos, sv)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>None</td>\n",
       "      <td>(front national, fr)</td>\n",
       "      <td>(sagte lawrie, de)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>None</td>\n",
       "      <td>(uchronie, fr)</td>\n",
       "      <td>(scanner artec scanrom, de)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>None</td>\n",
       "      <td>(lydnad, sv)</td>\n",
       "      <td>(film touchez pas, en)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>None</td>\n",
       "      <td>(homme accepte, fr)</td>\n",
       "      <td>(develop special trades and, en)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>None</td>\n",
       "      <td>(2, sv)</td>\n",
       "      <td>(phillip ranja, en)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>None</td>\n",
       "      <td>(et pépinot, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>None</td>\n",
       "      <td>(nancy, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>None</td>\n",
       "      <td>(steve gomer, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>None</td>\n",
       "      <td>(advance im, de)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>None</td>\n",
       "      <td>(ou af4c, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>None</td>\n",
       "      <td>(ray ventura, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>None</td>\n",
       "      <td>(dold brottslighet, sv)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>None</td>\n",
       "      <td>(cour, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>None</td>\n",
       "      <td>(lassen, de)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>None</td>\n",
       "      <td>(belyst, sv)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>None</td>\n",
       "      <td>(ist relativ, de)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>None</td>\n",
       "      <td>(aimer, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>None</td>\n",
       "      <td>(livbojar, sv)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>None</td>\n",
       "      <td>(émotionnels, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>None</td>\n",
       "      <td>(kusin ruth, sv)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>None</td>\n",
       "      <td>(otto in, de)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>None</td>\n",
       "      <td>(arthur piroton, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>None</td>\n",
       "      <td>(musik news oder, de)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>None</td>\n",
       "      <td>(c et chris udoh, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>None</td>\n",
       "      <td>(smartmove nv, de)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>None</td>\n",
       "      <td>(hus, sv)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>None</td>\n",
       "      <td>(album country small one, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>None</td>\n",
       "      <td>(av, sv)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>None</td>\n",
       "      <td>(browser so, de)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>None</td>\n",
       "      <td>(monuments historiques, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>None</td>\n",
       "      <td>(gallatin andy phillip, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>None</td>\n",
       "      <td>(of macintosh, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>None</td>\n",
       "      <td>(chief executive dg, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>None</td>\n",
       "      <td>(color, de)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>None</td>\n",
       "      <td>(hand inriktas, sv)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>None</td>\n",
       "      <td>(croft, de)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>None</td>\n",
       "      <td>(alla accepterade, sv)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>None</td>\n",
       "      <td>(sa vengeance, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>None</td>\n",
       "      <td>(music sony und, de)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>None</td>\n",
       "      <td>(social institution, sv)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>None</td>\n",
       "      <td>(att hon, sv)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>None</td>\n",
       "      <td>(y a, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>None</td>\n",
       "      <td>(topographe russe, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>None</td>\n",
       "      <td>(halvmesyr, sv)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>None</td>\n",
       "      <td>(relaxé, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>None</td>\n",
       "      <td>(aptitbeteende, sv)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>None</td>\n",
       "      <td>(intervention militaire, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>None</td>\n",
       "      <td>(sagte, de)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>None</td>\n",
       "      <td>(weil reuss in, de)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>None</td>\n",
       "      <td>(rewritable products promotion, de)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>None</td>\n",
       "      <td>(drogue, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>None</td>\n",
       "      <td>(land, sv)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>None</td>\n",
       "      <td>(easy dsl spezial, de)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>None</td>\n",
       "      <td>(reproduction très rapide absence, fr)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>None</td>\n",
       "      <td>(finanz, de)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>None</td>\n",
       "      <td>(what about nemax, de)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>None</td>\n",
       "      <td>(hat jedoch, de)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sv  \\\n",
       "0                      (jenna marbles, en)   \n",
       "1                            (results, en)   \n",
       "2                           (cukor et, fr)   \n",
       "3                     (hören war doch, de)   \n",
       "4              (nom de villebetmer et, fr)   \n",
       "5                       (sochi russia, en)   \n",
       "6                       (as president, en)   \n",
       "7                       (hinter axero, de)   \n",
       "8                           (lv stuff, en)   \n",
       "9                             (300 32, de)   \n",
       "10             (giovanni bellini 1505, en)   \n",
       "11                      (statt dessen, de)   \n",
       "12   (postbank easytrade per internet, de)   \n",
       "13                              (1971, fr)   \n",
       "14         (varvara yakovleva à titre, fr)   \n",
       "15                              (poet, en)   \n",
       "16                   (rock reggae pop, fr)   \n",
       "17                (it jenna mcmasters, en)   \n",
       "18                             (drupa, de)   \n",
       "19                         (davantage, fr)   \n",
       "20                              (i at, en)   \n",
       "21                           (fertile, fr)   \n",
       "22                     (telekom kappt, de)   \n",
       "23                          (anderson, en)   \n",
       "24                (und edgar bronfman, de)   \n",
       "25                              (bild, de)   \n",
       "26                   (de hattushili i, fr)   \n",
       "27            (toratane hara nobutaka, fr)   \n",
       "28                              (pete, en)   \n",
       "29                       (lara fabian, fr)   \n",
       "30                 (et de utilisation, fr)   \n",
       "31           (sony distribuera en dvd, fr)   \n",
       "32               (internet explorer 6, en)   \n",
       "33               (doppelter kapazität, de)   \n",
       "34                      (i felt angry, en)   \n",
       "35                   (den rosa riesen, de)   \n",
       "36                         (behandelt, de)   \n",
       "37                              (barn, en)   \n",
       "38                       (prerogative, en)   \n",
       "39                  (tarife bestätigt, de)   \n",
       "40                      (50 mark sind, de)   \n",
       "41                             (belle, en)   \n",
       "42                             (still, en)   \n",
       "43                  (namen travelstar, de)   \n",
       "44                 (sont dda ddha nna, fr)   \n",
       "45                          (partnern, de)   \n",
       "46    (of ethnocentrism or evaluating, en)   \n",
       "47               (anhörung in brüssel, de)   \n",
       "48                                    None   \n",
       "49                                    None   \n",
       "50                                    None   \n",
       "51                                    None   \n",
       "52                                    None   \n",
       "53                                    None   \n",
       "54                                    None   \n",
       "55                                    None   \n",
       "56                                    None   \n",
       "57                                    None   \n",
       "58                                    None   \n",
       "59                                    None   \n",
       "60                                    None   \n",
       "61                                    None   \n",
       "62                                    None   \n",
       "63                                    None   \n",
       "64                                    None   \n",
       "65                                    None   \n",
       "66                                    None   \n",
       "67                                    None   \n",
       "68                                    None   \n",
       "69                                    None   \n",
       "70                                    None   \n",
       "71                                    None   \n",
       "72                                    None   \n",
       "73                                    None   \n",
       "74                                    None   \n",
       "75                                    None   \n",
       "76                                    None   \n",
       "77                                    None   \n",
       "78                                    None   \n",
       "79                                    None   \n",
       "80                                    None   \n",
       "81                                    None   \n",
       "82                                    None   \n",
       "83                                    None   \n",
       "84                                    None   \n",
       "85                                    None   \n",
       "86                                    None   \n",
       "87                                    None   \n",
       "88                                    None   \n",
       "89                                    None   \n",
       "90                                    None   \n",
       "91                                    None   \n",
       "92                                    None   \n",
       "93                                    None   \n",
       "94                                    None   \n",
       "95                                    None   \n",
       "96                                    None   \n",
       "97                                    None   \n",
       "98                                    None   \n",
       "99                                    None   \n",
       "100                                   None   \n",
       "101                                   None   \n",
       "102                                   None   \n",
       "103                                   None   \n",
       "104                                   None   \n",
       "105                                   None   \n",
       "106                                   None   \n",
       "107                                   None   \n",
       "108                                   None   \n",
       "109                                   None   \n",
       "110                                   None   \n",
       "111                                   None   \n",
       "112                                   None   \n",
       "113                                   None   \n",
       "114                                   None   \n",
       "\n",
       "                                         en  \\\n",
       "0                             (hofheim, fr)   \n",
       "1                             (actives, fr)   \n",
       "2                          (wissen was, de)   \n",
       "3                                (1985, sv)   \n",
       "4                                (1905, sv)   \n",
       "5                              (lassen, de)   \n",
       "6                       (sa population, fr)   \n",
       "7              (expeditioner valbyråer, sv)   \n",
       "8                          (weg ins in, de)   \n",
       "9                                 (576, fr)   \n",
       "10                              (ingås, sv)   \n",
       "11                                 (ha, sv)   \n",
       "12                            (bromsar, sv)   \n",
       "13          (marcus andronicus annonce, fr)   \n",
       "14                                (tid, sv)   \n",
       "15                     (diskussion hat, de)   \n",
       "16                         (aigu clair, fr)   \n",
       "17                    (fusion mit time, de)   \n",
       "18                (kungsholmens byalag, sv)   \n",
       "19                         (vuxit fram, sv)   \n",
       "20                                (syn, sv)   \n",
       "21                          (system av, sv)   \n",
       "22                         (4 aggregat, sv)   \n",
       "23                            (erst in, de)   \n",
       "24                          (kritik an, de)   \n",
       "25                     (dem meldet the, de)   \n",
       "26                               (ljus, sv)   \n",
       "27                             (se bat, fr)   \n",
       "28                         (m² elastic, fr)   \n",
       "29                          (speed bei, de)   \n",
       "30                         (hästfordon, sv)   \n",
       "31                                 (nu, sv)   \n",
       "32                                (syn, sv)   \n",
       "33          (1976 american association, fr)   \n",
       "34                               (2011, fr)   \n",
       "35                               (sagt, sv)   \n",
       "36                              (nedan, sv)   \n",
       "37                           (thèse ou, fr)   \n",
       "38                        (invalides a, fr)   \n",
       "39                              (group, de)   \n",
       "40                            (irlande, fr)   \n",
       "41                         (pro domain, de)   \n",
       "42                        (royal servi, fr)   \n",
       "43             (the dream produite par, fr)   \n",
       "44                       (18 juin 2010, fr)   \n",
       "45                           (mesure m, fr)   \n",
       "46                             (piston, fr)   \n",
       "47                           (hit från, sv)   \n",
       "48                                 (um, de)   \n",
       "49               (edouard guillaud sur, fr)   \n",
       "50                        (ferroviaire, fr)   \n",
       "51                              (jones, fr)   \n",
       "52                               (bowl, fr)   \n",
       "53                       (5 boeing 787, fr)   \n",
       "54                           (inom eec, sv)   \n",
       "55                     (frère philippe, fr)   \n",
       "56                              (sears, de)   \n",
       "57                           (men ofta, sv)   \n",
       "58                     (front national, fr)   \n",
       "59                           (uchronie, fr)   \n",
       "60                             (lydnad, sv)   \n",
       "61                      (homme accepte, fr)   \n",
       "62                                  (2, sv)   \n",
       "63                         (et pépinot, fr)   \n",
       "64                              (nancy, fr)   \n",
       "65                        (steve gomer, fr)   \n",
       "66                         (advance im, de)   \n",
       "67                            (ou af4c, fr)   \n",
       "68                        (ray ventura, fr)   \n",
       "69                  (dold brottslighet, sv)   \n",
       "70                               (cour, fr)   \n",
       "71                             (lassen, de)   \n",
       "72                             (belyst, sv)   \n",
       "73                        (ist relativ, de)   \n",
       "74                              (aimer, fr)   \n",
       "75                           (livbojar, sv)   \n",
       "76                        (émotionnels, fr)   \n",
       "77                         (kusin ruth, sv)   \n",
       "78                            (otto in, de)   \n",
       "79                     (arthur piroton, fr)   \n",
       "80                    (musik news oder, de)   \n",
       "81                    (c et chris udoh, fr)   \n",
       "82                       (smartmove nv, de)   \n",
       "83                                (hus, sv)   \n",
       "84            (album country small one, fr)   \n",
       "85                                 (av, sv)   \n",
       "86                         (browser so, de)   \n",
       "87              (monuments historiques, fr)   \n",
       "88              (gallatin andy phillip, fr)   \n",
       "89                       (of macintosh, fr)   \n",
       "90                 (chief executive dg, fr)   \n",
       "91                              (color, de)   \n",
       "92                      (hand inriktas, sv)   \n",
       "93                              (croft, de)   \n",
       "94                   (alla accepterade, sv)   \n",
       "95                       (sa vengeance, fr)   \n",
       "96                     (music sony und, de)   \n",
       "97                 (social institution, sv)   \n",
       "98                            (att hon, sv)   \n",
       "99                                (y a, fr)   \n",
       "100                  (topographe russe, fr)   \n",
       "101                         (halvmesyr, sv)   \n",
       "102                            (relaxé, fr)   \n",
       "103                     (aptitbeteende, sv)   \n",
       "104            (intervention militaire, fr)   \n",
       "105                             (sagte, de)   \n",
       "106                     (weil reuss in, de)   \n",
       "107     (rewritable products promotion, de)   \n",
       "108                            (drogue, fr)   \n",
       "109                              (land, sv)   \n",
       "110                  (easy dsl spezial, de)   \n",
       "111  (reproduction très rapide absence, fr)   \n",
       "112                            (finanz, de)   \n",
       "113                  (what about nemax, de)   \n",
       "114                        (hat jedoch, de)   \n",
       "\n",
       "                                            fr  \\\n",
       "0                             (semaine de, en)   \n",
       "1                        (madame tussauds, en)   \n",
       "2                           (more details, en)   \n",
       "3                                   (divx, de)   \n",
       "4                              (chet clem, en)   \n",
       "5                          (zirka 20 euro, de)   \n",
       "6                             (irrelevant, en)   \n",
       "7                                 (liquid, en)   \n",
       "8                             (480 pixeln, de)   \n",
       "9                                 (balans, sv)   \n",
       "10                      (voice stammt den, de)   \n",
       "11                            (intressant, sv)   \n",
       "12                        (video miharris, en)   \n",
       "13                       (camp councillor, en)   \n",
       "14                       (quite a problem, en)   \n",
       "15                                (priser, sv)   \n",
       "16                    (prozess durch alle, de)   \n",
       "17                              (purposes, en)   \n",
       "18                            (term plans, en)   \n",
       "19                   (höchst dubios sagte, de)   \n",
       "20                        (patrick gordon, en)   \n",
       "21                                (1994 6, en)   \n",
       "22                               (portale, de)   \n",
       "23                     (anime fantasy and, en)   \n",
       "24                          (its pressure, en)   \n",
       "25                   (potential employers, en)   \n",
       "26                        (silicon valley, de)   \n",
       "27                (your favorite question, en)   \n",
       "28                    (formal equivalence, en)   \n",
       "29          (alternative courses delivery, en)   \n",
       "30           (by complementary misfortune, en)   \n",
       "31                              (primacom, de)   \n",
       "32                               (je nach, de)   \n",
       "33                      (bit ethnocentric, en)   \n",
       "34      (large enclosure under conditions, en)   \n",
       "35                               (trouble, en)   \n",
       "36                              (maj 1970, sv)   \n",
       "37                            (markfaunan, sv)   \n",
       "38                      (alla departement, sv)   \n",
       "39                      (jacques payer am, de)   \n",
       "40                              (ende mai, de)   \n",
       "41                              (des aims, de)   \n",
       "42            (his partner chris cardenas, en)   \n",
       "43                       (less legitimate, en)   \n",
       "44                          (opposite her, en)   \n",
       "45                             (nun alles, de)   \n",
       "46                 (comdirect muss sparen, de)   \n",
       "47   (sufficiently clear nor sufficiently, en)   \n",
       "48                (es ende letzten jahres, de)   \n",
       "49                                (nu ett, sv)   \n",
       "50                 (a charitable capacity, en)   \n",
       "51            (idea produces some puzzles, en)   \n",
       "52                                  (plus, de)   \n",
       "53        (siméon poisson reviewed galois, en)   \n",
       "54                     (talkline plant im, de)   \n",
       "55                 (aggression hos lämmel, sv)   \n",
       "56                           (equivalence, en)   \n",
       "57                        (1967 del 1 sos, sv)   \n",
       "58                          (sagte lawrie, de)   \n",
       "59                 (scanner artec scanrom, de)   \n",
       "60                      (film touchez pas, en)   \n",
       "61            (develop special trades and, en)   \n",
       "62                         (phillip ranja, en)   \n",
       "63                                        None   \n",
       "64                                        None   \n",
       "65                                        None   \n",
       "66                                        None   \n",
       "67                                        None   \n",
       "68                                        None   \n",
       "69                                        None   \n",
       "70                                        None   \n",
       "71                                        None   \n",
       "72                                        None   \n",
       "73                                        None   \n",
       "74                                        None   \n",
       "75                                        None   \n",
       "76                                        None   \n",
       "77                                        None   \n",
       "78                                        None   \n",
       "79                                        None   \n",
       "80                                        None   \n",
       "81                                        None   \n",
       "82                                        None   \n",
       "83                                        None   \n",
       "84                                        None   \n",
       "85                                        None   \n",
       "86                                        None   \n",
       "87                                        None   \n",
       "88                                        None   \n",
       "89                                        None   \n",
       "90                                        None   \n",
       "91                                        None   \n",
       "92                                        None   \n",
       "93                                        None   \n",
       "94                                        None   \n",
       "95                                        None   \n",
       "96                                        None   \n",
       "97                                        None   \n",
       "98                                        None   \n",
       "99                                        None   \n",
       "100                                       None   \n",
       "101                                       None   \n",
       "102                                       None   \n",
       "103                                       None   \n",
       "104                                       None   \n",
       "105                                       None   \n",
       "106                                       None   \n",
       "107                                       None   \n",
       "108                                       None   \n",
       "109                                       None   \n",
       "110                                       None   \n",
       "111                                       None   \n",
       "112                                       None   \n",
       "113                                       None   \n",
       "114                                       None   \n",
       "\n",
       "                                   de  \n",
       "0              (gendarmerie vont, fr)  \n",
       "1              (sovereign people, en)  \n",
       "2                     (comprimer, fr)  \n",
       "3               (die sooner when, en)  \n",
       "4                      (del 2 59, sv)  \n",
       "5                    (90 minutes, fr)  \n",
       "6                           (dem, sv)  \n",
       "7                     (att ge de, sv)  \n",
       "8                        (church, en)  \n",
       "9    (comme nan goldin printemps, fr)  \n",
       "10                (neutraliteten, sv)  \n",
       "11                  (15 november, sv)  \n",
       "12   (volunteers and soldiers of, en)  \n",
       "13                 (states until, en)  \n",
       "14                     (ges inte, sv)  \n",
       "15                      (en 2005, fr)  \n",
       "16                (mittlinje kan, sv)  \n",
       "17                   (zuckerberg, en)  \n",
       "18       (statens naturvårdsverk, sv)  \n",
       "19                     (jag inte, sv)  \n",
       "20              (gymnasiestudier, sv)  \n",
       "21   (adverb auxiliary verb main, en)  \n",
       "22                (limb geometry, en)  \n",
       "23              (1856 macnab fut, fr)  \n",
       "24                       (kuvert, sv)  \n",
       "25                 (kommissionen, sv)  \n",
       "26             (state commitment, en)  \n",
       "27                      (big ben, en)  \n",
       "28                     (bills in, en)  \n",
       "29                (fadern makten, sv)  \n",
       "30                 (will be able, en)  \n",
       "31         (michael smith writes, en)  \n",
       "32        (innerst inne inte att, sv)  \n",
       "33           (javafx mobile bien, fr)  \n",
       "34             (center and stuff, en)  \n",
       "35    (schweiz ch västtyskland d, sv)  \n",
       "36                  (eugene nida, en)  \n",
       "37                  (independent, en)  \n",
       "38        (christian rosencreutz, en)  \n",
       "39           (och inte mindre än, sv)  \n",
       "40                               None  \n",
       "41                               None  \n",
       "42                               None  \n",
       "43                               None  \n",
       "44                               None  \n",
       "45                               None  \n",
       "46                               None  \n",
       "47                               None  \n",
       "48                               None  \n",
       "49                               None  \n",
       "50                               None  \n",
       "51                               None  \n",
       "52                               None  \n",
       "53                               None  \n",
       "54                               None  \n",
       "55                               None  \n",
       "56                               None  \n",
       "57                               None  \n",
       "58                               None  \n",
       "59                               None  \n",
       "60                               None  \n",
       "61                               None  \n",
       "62                               None  \n",
       "63                               None  \n",
       "64                               None  \n",
       "65                               None  \n",
       "66                               None  \n",
       "67                               None  \n",
       "68                               None  \n",
       "69                               None  \n",
       "70                               None  \n",
       "71                               None  \n",
       "72                               None  \n",
       "73                               None  \n",
       "74                               None  \n",
       "75                               None  \n",
       "76                               None  \n",
       "77                               None  \n",
       "78                               None  \n",
       "79                               None  \n",
       "80                               None  \n",
       "81                               None  \n",
       "82                               None  \n",
       "83                               None  \n",
       "84                               None  \n",
       "85                               None  \n",
       "86                               None  \n",
       "87                               None  \n",
       "88                               None  \n",
       "89                               None  \n",
       "90                               None  \n",
       "91                               None  \n",
       "92                               None  \n",
       "93                               None  \n",
       "94                               None  \n",
       "95                               None  \n",
       "96                               None  \n",
       "97                               None  \n",
       "98                               None  \n",
       "99                               None  \n",
       "100                              None  \n",
       "101                              None  \n",
       "102                              None  \n",
       "103                              None  \n",
       "104                              None  \n",
       "105                              None  \n",
       "106                              None  \n",
       "107                              None  \n",
       "108                              None  \n",
       "109                              None  \n",
       "110                              None  \n",
       "111                              None  \n",
       "112                              None  \n",
       "113                              None  \n",
       "114                              None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get incorrectly predicted tokens by the perceptron and logistic regression models.\n",
    "index_class = {0:\"de\", 1:\"en\", 2:\"fr\", 3:\"sv\"}\n",
    "def get_incorrect_class(dev_pred, dev_y):\n",
    "    \"\"\"retrieve incorrectly predicted tokens, including text, gold label and predicted label\"\"\"\n",
    "    incorr_sys_class = defaultdict(list)\n",
    "    idx = 0\n",
    "    for pred_idx, gold_idx in zip(dev_pred, dev_y):\n",
    "        if pred_idx != gold_idx:\n",
    "            incorr_sys_class[(index_class[pred_idx])].append((dev.text[idx],index_class[gold_idx]))\n",
    "        idx += 1\n",
    "    return incorr_sys_class\n",
    "incorr_pcpt_sys_class = get_incorrect_class(pcpt_sys_dev_y, dev_y)\n",
    "incorr_lr_sys_class = get_incorrect_class(lr_sys_dev_y, dev_y)\n",
    "\n",
    "df = pd.DataFrame.from_dict(incorr_lr_sys_class, orient='index')\n",
    "pd.set_option('display.max_rows', df.transpose().shape[0]+1)\n",
    "df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01ea7f4",
   "metadata": {},
   "source": [
    "For both models, you should fine-tune hyperparameters and improve your feature extraction. Try to find a combination of features and hyperparameters which gives you optimal performance on the development data.\n",
    "\n",
    "For perceptron, you need to fine-tune at least:\n",
    "* Training epoch count\n",
    "\n",
    "For logistic regression, you need to fine-tune at least:\n",
    "* Training epoch count\n",
    "* Regularization strength\n",
    "* Type of regularization (l1 or l2)\n",
    "\n",
    "Both models include other hyperparameters which you can also tune if you like. This can help with performance.\n",
    "\n",
    "For both classifiers, you need to get f-score > 93% on the development data to get full score for this assignment and an improvement of at least 0.1%-points over your untuned f-scores.\n",
    "\n",
    "**HINT:** In order to use `l1` regularization, you need to provide the parameter `solver=\"liblinear\"` when initializing `LogisticRegression`. The default algorithm which is used for fitting model parameters [BFGS](https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm) cannot handle `l1`. \n",
    "\n",
    "In your report (question 7), you should describe the hyperparameter fine-tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17cff64f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fine tune features\n",
    "def char_ngram(text, maxn, maxlen):\n",
    "    ngram = []\n",
    "    for i in range(0, len(text) + 1 - maxn):\n",
    "        for j in range(i + maxn, min(i + maxn + 1, len(text) + 1)):\n",
    "            ngram.append(text[i:j])\n",
    "    return ngram\n",
    "def feature_extraction(data):\n",
    "    # extract features from text and gather langauge tags\n",
    "    data_features = []\n",
    "    for text in data.text:\n",
    "        features = {\n",
    "            \"char_unigram\" : char_ngram(text, 1, 70), # character unigram\n",
    "            \"char_bigram\" : char_ngram(text, 2, 70), # character bigram\n",
    "            \"char_trigram\" : char_ngram(text, 3, 70), # character trigram\n",
    "            \"char_quadgram\" : char_ngram(text, 4, 70), # character 4-gram\n",
    "            \"char_pentagram\" : char_ngram(text, 5, 70), # character 5-gram\n",
    "            \"en_word_no\": len([word for word in text.split(\" \") if word in en_df.inflected.iloc[1]]), # number of English inflected word\n",
    "            \"fr_word_no\": len([word for word in text.split(\" \") if word in fr_df.inflected.iloc[1]]), # number of French inflected word\n",
    "            \"de_word_no\": len([word for word in text.split(\" \") if word in de_df.inflected.iloc[1]]), # number of German inflected word\n",
    "            \"sv_word_no\": len([word for word in text.split(\" \") if word in sv_df.inflected.iloc[1]]), # number of Swedish inflected word\n",
    "            \"word_suff_1\": [word[-1:] for word in text.split(\" \")], # last character as word suffix\n",
    "            \"word_suff_2\": [word[-2:] for word in text.split(\" \")], # last two characters as word suffix\n",
    "            \"word_suff_3\": [word[-3:] for word in text.split(\" \")], # last three characters as word suffix\n",
    "            \"word_suff_4\": [word[-4:] for word in text.split(\" \")] # last four characters as word suffix\n",
    "        }\n",
    "        if len(list(set(text.split(\" \")) & set(['a', \"an\", \"the\", \"is\", \"are\", \"was\", \"were\"])))>0:  # existance of English common word\n",
    "            features[\"EN_common_word\"] = \"YES\"\n",
    "        if len(list(set(text.split(\" \")) & set([\"un\", \"une\", \"le\", \"la\", \"est\", \"de\", \"et\"])))>0: # existance of French common word, added \"de\", \"et\"\n",
    "            features[\"FR_common_word\"] = \"YES\"\n",
    "        if len(list(set(text.split(\" \")) & set([\"ein\", \"eine\", \"die\", \"der\", \"ist\", \"sind\"])))>0: # existance of German common word, added \"sind\"\n",
    "            features[\"DE_common_word\"] = \"YES\"\n",
    "        if len(list(set(text.split(\" \")) & set([\"en\", \"ett\", \"är\", \"var\", \"det\"])))>0:  # existance of Swedish common word\n",
    "            features[\"SV_common_word\"] = \"YES\"\n",
    "            \n",
    "        data_features.append(features)\n",
    "    return data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfe67fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, f-score: 0.8742532071673981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2, f-score: 0.9169028515911204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3, f-score: 0.9138680601352698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4, f-score: 0.9270857438263894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5, f-score: 0.9298338102599981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6, f-score: 0.9247733966142477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:7, f-score: 0.9319312270040501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8, f-score: 0.9307439067586734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:9, f-score: 0.9281312294931425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10, f-score: 0.9356688108919853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:11, f-score: 0.9339600223711402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:12, f-score: 0.9349152026341898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:13, f-score: 0.9353496058812679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:14, f-score: 0.9359238249441162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:15, f-score: 0.9345583306986962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:16, f-score: 0.932900783024593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:17, f-score: 0.9333946067607615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:18, f-score: 0.9324976928921618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:19, f-score: 0.9351876705552478\n",
      "Epoch:20, f-score: 0.9351876705552478\n",
      "Best epoch:14, best f-score: 0.9359238249441162\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning for the perceptron classifier: epoch from 1-20\n",
    "# Best epoch is 14, F1-scocre reached 0.9359 after tuning, and increased from 0.9073 from pre-tuning.\n",
    "def encode_and_train(train, dev, test, vectorizer, classifier):\n",
    "    \"\"\"get features for train, dev, and test and then vectorize. Then fit the classifier\"\"\"\n",
    "    train_features = feature_extraction(train)\n",
    "    dev_features= feature_extraction(dev)\n",
    "    test_features = feature_extraction(test)\n",
    "\n",
    "    train_X = vectorizer.fit_transform(train_features)\n",
    "    dev_X = vectorizer.transform(dev_features)\n",
    "    test_X = vectorizer.transform(test_features)\n",
    "\n",
    "    classifier.fit(train_X, train_y)\n",
    "    \n",
    "    return train_X, dev_X, test_X, classifier\n",
    "\n",
    "def evaluate(data_X, data_y, classifier):\n",
    "    \"\"\"predict based on features and then evaluate\"\"\"\n",
    "    sys_data_y = classifier.predict(data_X)\n",
    "    return f1_score(data_y, sys_data_y, average='macro')\n",
    "\n",
    "vectorizer = DictVectorizer()\n",
    "\n",
    "best_f_score = 0\n",
    "best_pcpt_epoch = 0\n",
    "\n",
    "for epoch in range(1,21):\n",
    "    classifier =  Perceptron(max_iter=epoch)\n",
    "    train_X, dev_X, test_X, classifier = encode_and_train(train, dev, test, vectorizer, classifier)\n",
    "    f_score = evaluate(dev_X, dev_y, classifier)\n",
    "    if f_score > best_f_score:\n",
    "        best_f_score = f_score\n",
    "        best_pcpt_epoch = epoch\n",
    "\n",
    "    print(f\"Epoch:{epoch}, f-score: {f_score}\")\n",
    "print(f\"Best epoch:{best_pcpt_epoch}, best f-score: {best_f_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5f37245-937d-4677-8611-18e2394ea33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Regularization:l1, strength:1, f-score: 0.9002930097241219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Regularization:l1, strength:5, f-score: 0.8464643084393764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Regularization:l1, strength:10, f-score: 0.8202520429463062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Regularization:l2, strength:1, f-score: 0.8755347989255238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Regularization:l2, strength:5, f-score: 0.8751960283155092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Regularization:l2, strength:10, f-score: 0.8755347989255238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2, Regularization:l1, strength:1, f-score: 0.9180331649258742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2, Regularization:l1, strength:5, f-score: 0.9245121149530815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2, Regularization:l1, strength:10, f-score: 0.912295801107267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2, Regularization:l2, strength:1, f-score: 0.9047338186578706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2, Regularization:l2, strength:5, f-score: 0.904386244041102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2, Regularization:l2, strength:10, f-score: 0.904386244041102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3, Regularization:l1, strength:1, f-score: 0.9231456166731965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3, Regularization:l1, strength:5, f-score: 0.936335421193456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3, Regularization:l1, strength:10, f-score: 0.9292953818739448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3, Regularization:l2, strength:1, f-score: 0.9190408130193648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3, Regularization:l2, strength:5, f-score: 0.9176816085621053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3, Regularization:l2, strength:10, f-score: 0.9176816085621053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4, Regularization:l1, strength:1, f-score: 0.9258131563600751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4, Regularization:l1, strength:5, f-score: 0.934687597838852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4, Regularization:l1, strength:10, f-score: 0.9313448032304897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4, Regularization:l2, strength:1, f-score: 0.931575579821555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4, Regularization:l2, strength:5, f-score: 0.929559839143032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4, Regularization:l2, strength:10, f-score: 0.9292277828131011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5, Regularization:l1, strength:1, f-score: 0.9205162919086651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5, Regularization:l1, strength:5, f-score: 0.935818996776758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5, Regularization:l1, strength:10, f-score: 0.9337473530415199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5, Regularization:l2, strength:1, f-score: 0.9331664023616205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5, Regularization:l2, strength:5, f-score: 0.9344822901739287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5, Regularization:l2, strength:10, f-score: 0.9345000310688987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6, Regularization:l1, strength:1, f-score: 0.9205465678730009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6, Regularization:l1, strength:5, f-score: 0.9327971136111463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6, Regularization:l1, strength:10, f-score: 0.9331456565810586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6, Regularization:l2, strength:1, f-score: 0.9337932514982336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6, Regularization:l2, strength:5, f-score: 0.9310870292845026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6, Regularization:l2, strength:10, f-score: 0.9320741640289443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:7, Regularization:l1, strength:1, f-score: 0.9189291470522258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:7, Regularization:l1, strength:5, f-score: 0.9304562291298004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:7, Regularization:l1, strength:10, f-score: 0.9331087205667489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:7, Regularization:l2, strength:1, f-score: 0.9351392493341757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:7, Regularization:l2, strength:5, f-score: 0.9327533228259786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:7, Regularization:l2, strength:10, f-score: 0.9317348645323398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8, Regularization:l1, strength:1, f-score: 0.9189273664678271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8, Regularization:l1, strength:5, f-score: 0.9277916212937847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8, Regularization:l1, strength:10, f-score: 0.9314217166570746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8, Regularization:l2, strength:1, f-score: 0.9354620684913761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8, Regularization:l2, strength:5, f-score: 0.9331008062369887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8, Regularization:l2, strength:10, f-score: 0.9310704874782771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:9, Regularization:l1, strength:1, f-score: 0.9182379213713093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:9, Regularization:l1, strength:5, f-score: 0.9251106809471046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:9, Regularization:l1, strength:10, f-score: 0.9271400603248506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:9, Regularization:l2, strength:1, f-score: 0.9354620684913761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:9, Regularization:l2, strength:5, f-score: 0.9324214571567866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:9, Regularization:l2, strength:10, f-score: 0.9314338765604083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10, Regularization:l1, strength:1, f-score: 0.917236008205115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10, Regularization:l1, strength:5, f-score: 0.9251148283424178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10, Regularization:l1, strength:10, f-score: 0.9278258221662505\n",
      "Epoch:10, Regularization:l2, strength:1, f-score: 0.9354620684913761\n",
      "Epoch:10, Regularization:l2, strength:5, f-score: 0.9324214571567866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10, Regularization:l2, strength:10, f-score: 0.9314338765604083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:11, Regularization:l1, strength:1, f-score: 0.9182371713708278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:11, Regularization:l1, strength:5, f-score: 0.923448483823986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:11, Regularization:l1, strength:10, f-score: 0.9261345217905219\n",
      "Epoch:11, Regularization:l2, strength:1, f-score: 0.9354620684913761\n",
      "Epoch:11, Regularization:l2, strength:5, f-score: 0.9324214571567866\n",
      "Epoch:11, Regularization:l2, strength:10, f-score: 0.9314338765604083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:12, Regularization:l1, strength:1, f-score: 0.916879148724496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:12, Regularization:l1, strength:5, f-score: 0.924138713762604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:12, Regularization:l1, strength:10, f-score: 0.9264524163396817\n",
      "Epoch:12, Regularization:l2, strength:1, f-score: 0.9354620684913761\n",
      "Epoch:12, Regularization:l2, strength:5, f-score: 0.9324214571567866\n",
      "Epoch:12, Regularization:l2, strength:10, f-score: 0.9314338765604083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:13, Regularization:l1, strength:1, f-score: 0.9175545894478974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:13, Regularization:l1, strength:5, f-score: 0.9254937713284773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:13, Regularization:l1, strength:10, f-score: 0.9234285313281125\n",
      "Epoch:13, Regularization:l2, strength:1, f-score: 0.9354620684913761\n",
      "Epoch:13, Regularization:l2, strength:5, f-score: 0.9324214571567866\n",
      "Epoch:13, Regularization:l2, strength:10, f-score: 0.9314338765604083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:14, Regularization:l1, strength:1, f-score: 0.9175912175882169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:14, Regularization:l1, strength:5, f-score: 0.9228089197436279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:14, Regularization:l1, strength:10, f-score: 0.9241368827093022\n",
      "Epoch:14, Regularization:l2, strength:1, f-score: 0.9354620684913761\n",
      "Epoch:14, Regularization:l2, strength:5, f-score: 0.9324214571567866\n",
      "Epoch:14, Regularization:l2, strength:10, f-score: 0.9314338765604083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:15, Regularization:l1, strength:1, f-score: 0.9172370352461823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:15, Regularization:l1, strength:5, f-score: 0.9241447890801382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:15, Regularization:l1, strength:10, f-score: 0.9247953745801273\n",
      "Epoch:15, Regularization:l2, strength:1, f-score: 0.9354620684913761\n",
      "Epoch:15, Regularization:l2, strength:5, f-score: 0.9324214571567866\n",
      "Epoch:15, Regularization:l2, strength:10, f-score: 0.9314338765604083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:16, Regularization:l1, strength:1, f-score: 0.9172299259199858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:16, Regularization:l1, strength:5, f-score: 0.9251535550638534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:16, Regularization:l1, strength:10, f-score: 0.9227986443910953\n",
      "Epoch:16, Regularization:l2, strength:1, f-score: 0.9354620684913761\n",
      "Epoch:16, Regularization:l2, strength:5, f-score: 0.9324214571567866\n",
      "Epoch:16, Regularization:l2, strength:10, f-score: 0.9314338765604083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:17, Regularization:l1, strength:1, f-score: 0.9168976118550846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:17, Regularization:l1, strength:5, f-score: 0.9238096070193504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:17, Regularization:l1, strength:10, f-score: 0.9238007526481078\n",
      "Epoch:17, Regularization:l2, strength:1, f-score: 0.9354620684913761\n",
      "Epoch:17, Regularization:l2, strength:5, f-score: 0.9324214571567866\n",
      "Epoch:17, Regularization:l2, strength:10, f-score: 0.9314338765604083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:18, Regularization:l1, strength:1, f-score: 0.9172425948866118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:18, Regularization:l1, strength:5, f-score: 0.9234682283112507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:18, Regularization:l1, strength:10, f-score: 0.9238037246411928\n",
      "Epoch:18, Regularization:l2, strength:1, f-score: 0.9354620684913761\n",
      "Epoch:18, Regularization:l2, strength:5, f-score: 0.9324214571567866\n",
      "Epoch:18, Regularization:l2, strength:10, f-score: 0.9314338765604083\n",
      "Epoch:19, Regularization:l1, strength:1, f-score: 0.9172425948866118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:19, Regularization:l1, strength:5, f-score: 0.9248148581879212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:19, Regularization:l1, strength:10, f-score: 0.9241540770396348\n",
      "Epoch:19, Regularization:l2, strength:1, f-score: 0.9354620684913761\n",
      "Epoch:19, Regularization:l2, strength:5, f-score: 0.9324214571567866\n",
      "Epoch:19, Regularization:l2, strength:10, f-score: 0.9314338765604083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:20, Regularization:l1, strength:1, f-score: 0.9172370352461823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:20, Regularization:l1, strength:5, f-score: 0.9241518540208125\n",
      "Epoch:20, Regularization:l1, strength:10, f-score: 0.9238182442987226\n",
      "Epoch:20, Regularization:l2, strength:1, f-score: 0.9354620684913761\n",
      "Epoch:20, Regularization:l2, strength:5, f-score: 0.9324214571567866\n",
      "Epoch:20, Regularization:l2, strength:10, f-score: 0.9314338765604083\n",
      "Best epoch:3, Best fegularization:l1, Best strength:5, Best f-score: 0.936335421193456\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning for the logistic regression classifier: epoch from 1-20, regularization using \"l1\" or \"l2\", and regularization strength using 1, 5, and 10\n",
    "# Best epoch is 3, Best fegularization is l1, Best strength is 5\n",
    "# F1-scocre reached 0.9363 after tuning, and increased from 0.9112 from pre-tuning.\n",
    "best_f_score = 0\n",
    "best_lr_epoch = 0\n",
    "best_regularization = \"\"\n",
    "best_strength = 0\n",
    "\n",
    "for epoch in range(1,21):\n",
    "    for regularization in [\"l1\",\"l2\"]:\n",
    "        for strength in [1,5,10]:\n",
    "            classifier =  LogisticRegression(penalty = regularization, C = strength, solver=\"liblinear\",max_iter=epoch)\n",
    "            train_X, dev_X, test_X, classifier = encode_and_train(train, dev, test, vectorizer, classifier)\n",
    "            f_score = evaluate(dev_X, dev_y, classifier)\n",
    "            if f_score > best_f_score:\n",
    "                best_f_score = f_score\n",
    "                best_lr_epoch = epoch\n",
    "                best_regularization = regularization\n",
    "                best_strength = strength\n",
    "\n",
    "            print(f\"Epoch:{epoch}, Regularization:{regularization}, strength:{strength}, f-score: {f_score}\")\n",
    "print(f\"Best epoch:{best_lr_epoch}, Best fegularization:{best_regularization}, Best strength:{best_strength}, Best f-score: {best_f_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e5e676-b1b7-4867-90bf-81dc89a2cfbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5316d0e",
   "metadata": {},
   "source": [
    "## 5. Evaluation (20 points)\n",
    "\n",
    "You should now evaluate your classifiers on the test data. Please also run significance tests to check whether the difference in their f-scores is statistically significant. You are free to choose between the t-test, Wilcoxon test or bootstrap sampling. Please use a threshold p-value of 0.5%. \n",
    "\n",
    "In your report (question 7), you should answer the following questions:\n",
    "\n",
    "* Is there a statistically significant difference between the perceptron and logistic regression classifiers? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2d6ff3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron model evaluation: 0.931567191192982\n",
      "Logistic regression model evaluation: 0.9380847040923915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "# evaluation of the perceptron model\n",
    "pcpt = Perceptron(max_iter = best_pcpt_epoch)\n",
    "train_X, dev_X, test_X, classifier = encode_and_train(train, dev, test, vectorizer, pcpt)\n",
    "pcpt_test_y = pcpt.predict(test_X)\n",
    "pcpt_f_score = f1_score(test_y, pcpt_test_y, average=\"macro\")\n",
    "print(f\"Perceptron model evaluation: {pcpt_f_score}\")\n",
    "\n",
    "# evaluation of the logistic regression model\n",
    "lr = LogisticRegression(penalty = best_regularization, C = best_strength, solver=\"liblinear\",max_iter=best_lr_epoch)\n",
    "train_X, dev_X, test_X, classifier = encode_and_train(train, dev, test, vectorizer, lr)\n",
    "lr_test_y = lr.predict(test_X)\n",
    "lr_f_score = f1_score(test_y, lr_test_y, average=\"macro\")\n",
    "\n",
    "print(f\"Logistic regression model evaluation: {lr_f_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe36abbb-70c3-44f8-8c5e-b625d7d0aafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Perceptron f1 socre: 0.9311085948392679\n",
      "Mean Logistic regression f1 socre: 0.9382994257764595\n",
      "Wilcoxon signed rank test: WilcoxonResult(statistic=8.0, pvalue=0.048828125)\n"
     ]
    }
   ],
   "source": [
    "# testing whether significant difference exists in the performance of the two models.\n",
    "# split the test dataset into ten non-overlapping portions, and run evaluation of each model on each portion. \n",
    "# Then use a wilcoxon signed rank test to test whehter the performance of the two models is significantly different.\n",
    "pcpt_f_scores = []\n",
    "lr_f_scores = []\n",
    "\n",
    "STEP = int(len(test)/10 +1)\n",
    "\n",
    "test_sample_y = label_encoder.transform(test.language)\n",
    "\n",
    "vectorizer = DictVectorizer()\n",
    "train_features = feature_extraction(train)\n",
    "test_features = feature_extraction(test)\n",
    "train_X = vectorizer.fit(train_features)\n",
    "test_X = vectorizer.transform(test_features)\n",
    "\n",
    "pcpt_test_y = pcpt.predict(test_X)\n",
    "lr_test_y = lr.predict(test_X)\n",
    "\n",
    "for i in range(0, 3000, STEP):\n",
    "    pcpt_f_score = f1_score(test_sample_y[i:i+STEP], pcpt_test_y[i:i+STEP], average=\"macro\")\n",
    "    lr_f_score = f1_score(test_sample_y[i:i+STEP], lr_test_y[i:i+STEP], average=\"macro\")\n",
    "    pcpt_f_scores.append(pcpt_f_score)\n",
    "    lr_f_scores.append(lr_f_score)\n",
    "\n",
    "print(f\"Mean Perceptron f1 socre: {np.average(pcpt_f_scores)}\")\n",
    "print(f\"Mean Logistic regression f1 socre: {np.average(lr_f_scores)}\")\n",
    "print(f\"Wilcoxon signed rank test: {wilcoxon(pcpt_f_scores, lr_f_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9282a5b6",
   "metadata": {},
   "source": [
    "Some languages will be easier to tell apart than others. We might, for example, guess that German and Swedish will be hard to tell apart, because these languages are quite similar. Perhaps English and Swedish will be easier to distinguish? \n",
    "\n",
    "Use the sklearn function [sklearn.metrics.confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) to generate a [confusion matrix](https://www.w3schools.com/python/python_ml_confusion_matrix.asp) for your classifiers on the **development data**. \n",
    "\n",
    "If you want, you can plot the confusion matrix using [sklearn.metrics.ConfusionMatrixDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html).\n",
    "\n",
    "In your report (question 7), you should answer the following questions: \n",
    "\n",
    "* Which two languages are confused most often? \n",
    "* Why do you think these two languages are difficult to tell apart? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c58f0834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# perceptron regression confusion matrix\n",
    "pcpt_sys_dev_y = pcpt.predict(dev_X)\n",
    "\n",
    "pcpt_confusion_matrix = metrics.confusion_matrix(dev_y, pcpt_sys_dev_y)\n",
    "\n",
    "pcpt_cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = pcpt_confusion_matrix, display_labels = [\"de\", \"en\", \"fr\", \"sv\"])\n",
    "\n",
    "pcpt_cm_display.plot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# logistic regression confusion matrix\n",
    "lr_sys_dev_y = lr.predict(dev_X)\n",
    "\n",
    "lr_confusion_matrix = metrics.confusion_matrix(dev_y, lr_sys_dev_y)\n",
    "\n",
    "lr_cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = lr_confusion_matrix, display_labels = [\"de\", \"en\", \"fr\", \"sv\"])\n",
    "\n",
    "lr_cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd9088c",
   "metadata": {},
   "source": [
    "## 6. Top-features (20 points)\n",
    "\n",
    "You will now extract features which have large parameter values. These are features which your models emphasize strongly in classification, so they should be very informative.\n",
    "\n",
    "Find the 10 strongest features for the English class (the 10 features with the highest parameter values in the en parameter vectors) and the 10 most positive  features for the French class. Find these features both for your perceptron and logistic regression models. \n",
    "\n",
    "Note, that: \n",
    "\n",
    "* You will need to access the string representations of your features. `vectorizer.get_feature_names()` will help here. \n",
    "* You'll also need to access the parameter vectors of your models. These you can get using `model.coef_[i]`, where `model` is either you logistic regression model or your perceptron model, and `i` is the ID number of the class. \n",
    "* You'll need to use `encoder.classes_` to figure out which ID number corresponds to which language tag (de, en, fr or sv). \n",
    "\n",
    "In your report (question 7), you should answer the following questions:\n",
    "1. Do these features correspond to your intuition?\n",
    "1. Do the perceptron and logistic regression models find similar top-features?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05470bff-6781-4dd9-bc04-11c621314bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de' 'en' 'fr' 'sv']\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# get label and index correspondance\n",
    "print(label_encoder.classes_)\n",
    "print(label_encoder.transform(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "566a10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get string representation of features\n",
    "vectorizer = DictVectorizer()\n",
    "train_features = feature_extraction(train)\n",
    "train_X = vectorizer.fit_transform(train_features)\n",
    "features = vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b3c68ce-9046-4548-bb9f-1088ab1a1db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- perceptron model top features -------------\n",
      "------------- English top features -------------\n",
      "char_bigram=ed\n",
      "char_trigram=the\n",
      "char_bigram= c\n",
      "word_suff_2=ed\n",
      "word_suff_1=y\n",
      "word_suff_3=and\n",
      "char_bigram=ea\n",
      "EN_common_word=YES\n",
      "word_suff_4=and\n",
      "char_bigram=th\n",
      "------------- French top features -------------\n",
      "word_suff_3=les\n",
      "char_trigram= se\n",
      "char_bigram=ai\n",
      "word_suff_2=nt\n",
      "char_unigram=è\n",
      "word_suff_3=en\n",
      "word_suff_4=en\n",
      "char_bigram=te\n",
      "char_unigram=é\n",
      "FR_common_word=YES\n",
      "------------- logistic regression model top features -------------\n",
      "------------- English top features -------------\n",
      "char_pentagram=later\n",
      "word_suff_4=yeah\n",
      "word_suff_4=you\n",
      "word_suff_3=oh\n",
      "char_pentagram= patt\n",
      "char_quadgram=hire\n",
      "word_suff_3=ome\n",
      "word_suff_4=nasa\n",
      "char_quadgram=reer\n",
      "word_suff_4=two\n",
      "------------- French top features -------------\n",
      "word_suff_4=voir\n",
      "word_suff_2=y\n",
      "word_suff_4=ans\n",
      "char_trigram=eur\n",
      "char_pentagram= cett\n",
      "word_suff_3=bre\n",
      "char_pentagram=du de\n",
      "char_bigram=vé\n",
      "char_unigram=è\n",
      "char_quadgram=kesp\n"
     ]
    }
   ],
   "source": [
    "# get the top 10 features for English and French for both models\n",
    "# perceptron model\n",
    "print(\"------------- perceptron model top features -------------\")\n",
    "print(\"------------- English top features -------------\")\n",
    "top_10_en_feature_index = np.argsort(pcpt.coef_[1])[-10:]\n",
    "for idx in top_10_en_feature_index:\n",
    "    print(features[idx])\n",
    "\n",
    "print(\"------------- French top features -------------\")\n",
    "top_10_fr_feature_index = np.argsort(pcpt.coef_[2])[-10:]\n",
    "for idx in top_10_fr_feature_index:\n",
    "    print(features[idx])\n",
    "    \n",
    "# logistic regression model\n",
    "print(\"------------- logistic regression model top features -------------\")\n",
    "print(\"------------- English top features -------------\")\n",
    "lr_top_10_en_feature_index = np.argsort(lr.coef_[1])[-10:]\n",
    "for idx in lr_top_10_en_feature_index:\n",
    "    print(features[idx])\n",
    "print(\"------------- French top features -------------\")\n",
    "lr_top_10_fr_feature_index = np.argsort(lr.coef_[2])[-10:]\n",
    "for idx in lr_top_10_fr_feature_index:\n",
    "    print(features[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6d1563",
   "metadata": {},
   "source": [
    "## 7. Short report (10 points)\n",
    "\n",
    "Write a short report (half a page) describing what you did in this assignment. Please include answers to the questions posed in each individual assignment 1-6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac51f0a-a24b-41b5-b10d-0b126b16c22a",
   "metadata": {},
   "source": [
    "### Overview\n",
    "In this assignment, I trained two classifiers to classify language based on given text. Firstly, I loaded datasets (train, development and test) of sentence fragment text of four different languages, incluing German, English, French, and Swedish. Secondly, I came up with some features and then vectorized the features. Then I build two classifiers, one Perceptron classifier and one Logistic regression classifier. The two classifiers then got fine tuned using the development dataset and evaluated using test dataset. Then I comparied the performance of the two classifiers, and I plotted the confusion matrix of each classifier to exhibit which language is usually mis-classified. Finally, I extracted the top features found by the two classifers when predicting English and French. The following paragraphs will answer questions in each task.\n",
    "### Description on initial features (task 2)\n",
    "The initail features that I proposed were on three categories, inclduing character n-gram, number of inflected words, and common words in each langauge. Specifically, character n-gram features include character bi-gram and tri-gram features. Number of inflected words features include the number of inflected words in a given sentence fragmant for each langauge. For the common words features, I came up with four common words lists, one for each language. The lists contain words such as articles, determiners, and different forms of be-verbs in each language. Then I proposed features that check whether the given text contains any word in the lists.\n",
    "### Discuss why performance of the DummyClassifier is poor (task 3)\n",
    "The DummyClassifier trained in task 3 only returns the most frequent label that it observed in the training dataset. In our case, labels in the training and development dataset are roughly distributed, and the most frequent label in the training is 2 (French) which is the least frequent label in the development dataset (takes less than 25%). Since the DummyClassifier only predict the most frequent lable in the training dataset, the True Positive cases for the other three labels is zero, which results in F1 score of 0 for those labels. For the 2 (French) label, the F1 score is slightly below 0.4, which results in a macro average F1 score just below 0.1.\n",
    "### Hyperparameter fine tuning (task 4)\n",
    "Apart from tuning the hyperparameters, I also improved my feature set. \n",
    "After I inspected the incorrectly classified token, I noticed that my features did not capture words that only has one character (e.g. y in French), and I noticed that some word would easily be classified by its suffix (e.g. s in English, gue in French). Hence, I added some features to the character n-gram inclduing unigram, 4-gram and 5-gram, and added some suffixing features includling the last character of each word, the last two characters of each word, the last three characters of each word, and the last four characters of each word.\n",
    "\n",
    "For the Perceptron model, I only tuned the training epoch from 1 to 20. The results of the tuning process shows the best epoch is 14, and the F1-scocre reached 0.9359 after tuning, which increased from 0.9073 at pre-tuning.\n",
    "For the Logistic regression model, I tuned the training epoch from 1 to 20, chose regularization method from \"l1\" and \"l2\", and chose regularization strength from 1, 5, and 10. The results of the tuning process shows the best epoch is 3, the best fegularization is l1, and the best strength is 5. The model reached F1-scocre of 0.9363 after tuning, which increased from 0.9112 at pre-tuning.\n",
    "### Discussion on statistic test results (task 5)\n",
    "The results of an Wilcoxon Signed Rank test showed that the p value is 0.049, which is greater than our threshold 0.005. Therefore, there is no significant difference between the performance of the Perceptron and the Logistric regression classifier.\n",
    "### Most confused two languages (task 5)\n",
    "The confusion matrices of both the Perceptron classifier and the logistic regression classifier show that English and French got confused by both models most often. The Perceptron classifer mis-classifed 44 English sentences as French, and 21 French sentence as English, results in a total number of 65 which outnumbers all other pairs of languages. The Logistic regression classifer mis-classifed 28 English sentences as French, and 29 French sentence as English, results in a total number of 57 which also outnumbers all other pairs of languages. This might be because that English borrowed a lot of words from French in the history. For instance, English words population, problem, and question are borrowed from French.\n",
    "### Discussion on the top feature (task 6)\n",
    "I don't speak French so I don't have speaker intuition for French. The following discssion is on the top features of English.\n",
    "The top features found by the two classifiers are quite different. The top features used by the Perceptron classsifer look more intuitive to me than the top features used by the Logistic regression classifer. For the Perceptron classifier, apart from English common words, the top ranking features include character bigram -th-, bigram -ea-, suffix -ed, suffix -y, and suffix -and, which are all common forms in English but rare in other languages.\n",
    "\n",
    "The top features used by the Logistic regression classifer are less intuitive. For instance, -two, -you, -yeah as suffices were used as top features. However they could only be as one specific word not as suffices. The character n-gram features, such as -hire-, -nasa-, -later-, -reer-, - patt- are also not as common as features like -th- mentioned above. Therefore, I think the features found by the Perceptron classifier is more sensible than those found by the Logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9d014a-d287-45c7-96b6-6ac2f3ca5b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
