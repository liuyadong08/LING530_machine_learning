{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1: KNN classification\n",
    "\n",
    "In this homework assignment, we'll implement a KNN classifier using elementary Python functionality. We will then train and test the classifier on phonetic data and compare our implementation to the sklearn implementation `sklearn.neighbors.KNeighborsClassifier`.\n",
    "\n",
    "Before you start, rename the notebook as `HW1_KNN_firstname.ipynb`. E.g. `HW1_KNN_miikka.ipynb`.\n",
    "\n",
    "Our tasks include:\n",
    "\n",
    "1. Reading training and test data in pickle format\n",
    "1. Implementing distance functions for kNN\n",
    "1. Majority baseline\n",
    "1. Implementing the kNN classifier\n",
    "1. Tuning the k parameter for kNN\n",
    "1. Comparing your implementation to sklearn\n",
    "1. Evaluation\n",
    "\n",
    "Grading criteria for code:\n",
    "\n",
    "* Readability of code\n",
    "* Correctness of code and solution\n",
    "* Appropriate code commenting\n",
    "* Your code should be reasonably efficient. No need to optimize too much but it should be possible to run the entire notebook in 15 minutes.\n",
    "\n",
    "Grading criteria for half-page report (in assignment 7. Evaluation):\n",
    "\n",
    "* Clear explanation of what you did\n",
    "* Clear explanation of your observations concerning the output of the classifier.\n",
    "\n",
    "The **deadline for this assignment is Sunday October 16 at 23:59 PT**. Please upload your notebook `HW1_KNN_firstname.ipynb` on Canvas by the deadline. No need to include the datasets.\n",
    "\n",
    "Let's start by importing some useful modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pickle\n",
    "import sklearn.metrics\n",
    "import sklearn.preprocessing\n",
    "import sklearn.neighbors\n",
    "import sklearn.dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading data (15 points)\n",
    "\n",
    "You should download the datafiles `phon.train.pkl` and `phon.test.pkl` from Canvas and upload them to Google Colab (if you complete this homework on Colab).\n",
    "\n",
    "Start by reading the datasets into two variables `train_and_dev` (containing the training set) and `test` (containing the test set) using the `pickle` Python built-in module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "with open(\"phon.train.pkl\",\"rb\") as file:\n",
    "    train_and_dev = pickle.load(file)\n",
    "with open(\"phon.test.pkl\",\"rb\") as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first training example and the length of the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first training example:  {'vowel': 'AH', 'word': 'COVER', 'F1': 608.5, 'F2': 1322.2}\n",
      "length of training and dev:  2804\n",
      "length of test:  700\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "print(\"first training example: \", train_and_dev[0])\n",
    "print(\"length of training and dev: \", len(train_and_dev))\n",
    "print(\"length of test: \", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is no separate development file, we will need to start by separating the train set into a training and development split. Store the 300 first examples in `train_and_dev` into a list called `dev` and the remaining examples in a list called `train`.\n",
    "\n",
    "You can check that the combined length of `train` and `dev` is the same as the length of the `train_and_dev` list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dev:  300\n",
      "length of train:  2504\n",
      "length of separated train and dev:  2804\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "dev = train_and_dev[:300]\n",
    "print(\"length of dev: \", len(dev))\n",
    "train = train_and_dev[300:]\n",
    "print(\"length of train: \", len(train))\n",
    "print(\"length of separated train and dev: \", len(dev)+len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few [assertions](https://www.w3schools.com/python/ref_keyword_assert.asp) to check that your code is working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assertions to check your code\n",
    "assert(len(train) == 2504)\n",
    "assert(len(dev) == 300)\n",
    "assert(len(test) == 700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The examples in `train`, `dev` and `test` are Python dictionaries:\n",
    "    \n",
    "```\n",
    "{'vowel': 'ER', 'word': 'FLOWER', 'F1': 712.0, 'F2': 1715.5}\n",
    "```\n",
    "\n",
    "Each example contains a `\"vowel\"` field which tells you the true vowel corresponding to this example. The examples also contain two format frequencies `\"F1\"` and `\"F1\"`. Our task is to build a classifier which can classify examples by vowel based on their formant frequencies.\n",
    "\n",
    "We will now write some data preprocessing code. The aim is to convert examples in dictionary format to an input tuple and output label:\n",
    "\n",
    "```\n",
    "input: (712.0, 1715.5), output: 0\n",
    "```\n",
    "\n",
    "The first value in the tuple represents the F1 formant and the second one represents the F2 formant. The output is a numerical code representing the vowel (e.g. \"ER\").\n",
    "\n",
    "You should use [`sklearn.preprocessing.LabelEncoder()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) to convert your vowel labels to numerical labels. Start by initializing the label encoder. If you need help, check the KNN practical work from lecture 5. You can then call the `fit()` function of the label encoder on a list containing all the vowel labels (e.g. `\"ER\"`) to train the label encoder. Store the labels for the train set in a list `train_y`, for the development set in `dev_y` and for the test set in `test_y`.\n",
    "\n",
    "You should store the input examples (e.g. `(712.0, 1715.5)`) in the lists `train_X`, `dev_X`, `test_X`.\n",
    "\n",
    "Miikka's first train example looks like this (you class number might be different):\n",
    "```\n",
    ">>> print(train_X[0])\n",
    "(712.0, 1715.5)\n",
    "\n",
    ">>> print(train_y[0])\n",
    "7\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "label_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "train_label = [item[\"vowel\"] for item in train]\n",
    "dev_label = [item[\"vowel\"] for item in dev]\n",
    "test_label = [item[\"vowel\"] for item in test]\n",
    "label_encoder.fit(train_label+dev_label+test_label)\n",
    "\n",
    "def get_input_output(data, label_encoder):\n",
    "    \"get X from datasets and y from label_encoder\"\n",
    "    X=list()\n",
    "    y=list()\n",
    "    for item in data:\n",
    "        f1 = float(item[\"F1\"])\n",
    "        f2 = float(item[\"F2\"])\n",
    "        X.append((f1, f2))\n",
    "        y.append(label_encoder.transform([item[\"vowel\"]])[0])\n",
    "    return X, y\n",
    "train_X, train_y = get_input_output(train, label_encoder)\n",
    "dev_X, dev_y = get_input_output(dev, label_encoder)\n",
    "test_X, test_y = get_input_output(test, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few assertions to check that your code works properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assertions to check your code\n",
    "\n",
    "import numbers\n",
    "assert len(train_X[0]) == 2\n",
    "assert isinstance(train_X[0][0], numbers.Number)\n",
    "assert isinstance(train_X[0][1], numbers.Number)\n",
    "assert isinstance(train_y[0], numbers.Integral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many classes does the dataset contain? You can check this by printing the length of the list `label_encoder._classes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of vowels:  ['AA' 'AE' 'AH' 'AO' 'AW' 'AY' 'EH' 'ER' 'EY' 'IH' 'IY' 'OW' 'OY' 'UH'\n",
      " 'UW']\n",
      "number of vowels:  15\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "print(\"type of vowels: \", label_encoder.classes_)\n",
    "print(\"number of vowels: \", len(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Distance functions (5 points)\n",
    "\n",
    "You should now implement two distance functions `euclidean_dist()` and `manhattan_dist()`. Both take two lists of numbers `x1` and `x2` as input and return their Euclidean and Mahattan distance, respectively. E.g.\n",
    "\n",
    "```\n",
    "euclidean_dist((1,2,3,4), (2,3,4,5)) == 2\n",
    "```\n",
    "\n",
    "You should not rely on library implementations of these functions. Implement them yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "def euclidean_dist(coord1, coord2):\n",
    "    \"calculate the euclidean distance between two coordinates\"\n",
    "    sqr_dist = 0\n",
    "    for x, y in zip(coord1, coord2):\n",
    "        sqr_dist += (x-y)**2\n",
    "    return sqr_dist ** 0.5\n",
    "\n",
    "def manhattan_dist(coord1, coord2):\n",
    "    \"calculate the manhattan distance between two coordinates\"\n",
    "    man_dist = 0\n",
    "    for x, y in zip(coord1, coord2):\n",
    "        man_dist += abs(x-y)\n",
    "    return man_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few assertions to check that your code works properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assertions to check your code\n",
    "assert euclidean_dist((1,1,1), (1,1,1)) == 0\n",
    "assert euclidean_dist((1,2,3,4), (2,3,4,5)) == 2\n",
    "assert euclidean_dist((2,3,4,5), (1,2,3,4)) == 2\n",
    "assert manhattan_dist((1,1,1), (1,1,1)) == 0\n",
    "assert manhattan_dist((1,2,3,4), (2,3,4,5)) == 4\n",
    "assert manhattan_dist((2,3,4,5), (1,2,3,4)) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Majority baseline (5 points)\n",
    "\n",
    "Implement a majority baseline and evaluate it on the development data. You are allowed to use [`sklearn.dummy.DummyClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html).\n",
    "\n",
    "Your accuracy should be around `13%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12666666666666668"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "baseline = sklearn.dummy.DummyClassifier(strategy=\"most_frequent\")\n",
    "baseline.fit(train_X, train_y)\n",
    "\n",
    "baseline.score(dev_X, dev_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. KNN classifier (20 points)\n",
    "\n",
    "We'll now implement a function `knn_classify_ex` which takes the following parameters:\n",
    "\n",
    "* `x` an example like `(505.1, 1201.5)`\n",
    "* `train_X` and `train_y` are the training examples (inputs and classes)\n",
    "* `k` represents the k parameter for the kNN algorithm\n",
    "* dist_func is either your Euclidean distance function `euclidean_dist` or Manhattan distance function `manhattan_dist`.\n",
    "\n",
    "The function `knn_classify_ex` finds the `k` datapoints in `train_X` which are closest to `x`. It then finds their classes and returns the majority class. E.g. if `k == 3` and among the 3 closest points to x there are 2 examples with class `0` and one with class `1`, then you should return 0. Importantly, check that the function returns a single class number.\n",
    "\n",
    "Especially for smaller values of `k`, ties can easily happen and there might not exist a clear majority class. In this case, you may return an arbitrary class chosen among the most frequent classes. \n",
    "\n",
    "**Hint:** There are several ways to implement this function but it can be a good idea to first form a list of `(distance, class)` pairs and then sort this list into descending numerical order:\n",
    "\n",
    "```\n",
    ">>> l = [(1,0), (1.1,1), (0.1, 2), (0.5, 2)]\n",
    ">>> l.sort()\n",
    "print(l)\n",
    "```\n",
    "\n",
    "**Hint:** [`Counter`](https://docs.python.org/3/library/collections.html#collections.Counter) from the Python `collections` module can be useful for majority voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "def knn_classify_ex(x, train_X, train_y, k, dist_func):\n",
    "    \"build knn classifier for one example\"\n",
    "    dist_class = list()\n",
    "    for fmts, vowel in zip(train_X, train_y):\n",
    "        if dist_func == \"euclidean\":\n",
    "            dist = euclidean_dist(x, fmts)\n",
    "        elif dist_func == \"manhattan\":\n",
    "            dist = manhattan_dist(x, fmts)\n",
    "        dist_class.append((dist, vowel)) # get (distance, class) list\n",
    "    dist_class.sort() # sort the list by distance\n",
    "    nearest_classes = [ex[1] for ex in dist_class[:k]] # get the classes for the k nearest items\n",
    "    pred_class = Counter(nearest_classes).most_common(1)[0][0] # get the majority class\n",
    "    return pred_class\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now implement a function `knn_classify` which applies `knn_classify_ex` to every example in a dataset. It takes the following parameters:\n",
    "\n",
    "* `data` a dataset (in our case this will be either the development or test data).\n",
    "* `train_X` and `train_y` see above\n",
    "* `k` see above\n",
    "* `dist_func` see above \n",
    "\n",
    "The function returns a list of classes, one for each example in `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "def knn_classify(data, train_X, train_y, k, dist_func):\n",
    "    \"build knn classifier for a dataset\"\n",
    "    pred_y = list()\n",
    "    for ex in data:\n",
    "        y = knn_classify_ex(ex, train_X, train_y, k, dist_func)\n",
    "        pred_y.append(y)\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `knn_classify` on the development set `dev_X` using `k == 1` and `euclidean_dist`. Store the output in the list `sys_dev_y`. Then use [`sklearn.metrics.accuracy_score`]() to find the accuracy of the 1NN classifier. \n",
    "\n",
    "Your accuracy should exceed 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26666666666666666"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "sys_dev_y = knn_classify(dev_X, train_X, train_y, 1, \"euclidean\")\n",
    "sklearn.metrics.accuracy_score(dev_y, sys_dev_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tuning the k parameter (15 points)\n",
    "\n",
    "Train kNN classifiers for k in the range 1-50 and using different distance functions (Euclidean or Manhattan). For each k, check the accuracy of the classifier on the development set. Identify the best k and distance function based on development accuracy. \n",
    "\n",
    "Your best accuracy should be substantially higher than for the 1NN classifier. You should be able to get above 40%. \n",
    "\n",
    "Since we are running 100 experiments, it is important that your implementation of `knn_classify_ex` is reasonably fast. If it is, running all the experiments can take around five minutes but should not take much longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.42333333333333334, 20, 'euclidean'), (0.42, 44, 'euclidean'), (0.42, 39, 'euclidean'), (0.4166666666666667, 42, 'euclidean'), (0.4166666666666667, 40, 'euclidean'), (0.4166666666666667, 38, 'euclidean'), (0.41333333333333333, 45, 'euclidean'), (0.41333333333333333, 43, 'euclidean'), (0.41333333333333333, 41, 'euclidean'), (0.41333333333333333, 37, 'euclidean')]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "accuracy_k_dist_func = list() \n",
    "for k in range(1, 51):\n",
    "    for dist_func in [\"euclidean\", \"manhattan\"]:\n",
    "        pred_dev_y = knn_classify(dev_X, train_X, train_y, k, dist_func)\n",
    "        accuracy = sklearn.metrics.accuracy_score(dev_y, pred_dev_y)\n",
    "        accuracy_k_dist_func.append((accuracy, k, dist_func))\n",
    "accuracy_k_dist_func.sort(reverse=True)\n",
    "print(accuracy_k_dist_func[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the same experiment but this time using F-score instead of accuracy. You can use [`sklearn.metrics.f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html). Again, identify the best k and distance function which maximize the F-score. Are these the same as for accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.39, 50, 'manhattan'), (0.39, 50, 'euclidean'), (0.39, 49, 'manhattan'), (0.39, 49, 'euclidean'), (0.39, 48, 'manhattan'), (0.39, 48, 'euclidean'), (0.39, 47, 'manhattan'), (0.39, 47, 'euclidean'), (0.39, 46, 'manhattan'), (0.39, 46, 'euclidean')]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "f1_k_dist_func = list() \n",
    "for k in range(1, 51):\n",
    "    for dist_func in [\"euclidean\", \"manhattan\"]:\n",
    "        pred_dev_y = knn_classify(dev_X, train_X, train_y, k, dist_func)\n",
    "        f1 = sklearn.metrics.f1_score(dev_y, pred_dev_y, average=\"macro\")\n",
    "        f1_k_dist_func.append((accuracy, k, dist_func))\n",
    "f1_k_dist_func.sort(reverse=True)\n",
    "print(f1_k_dist_func[:10])\n",
    "\n",
    "# f1 score is lower than the accuracy score for the same k and distance function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison to sklearn (5 points)\n",
    "\n",
    "Train an [`sklearn.neighbors.KNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) on your `train_X` and `train_y` data using your best k and best distance metric (identified using accuracy, not F-score).\n",
    "\n",
    "If you are using Euclidean distance, you can initialize the KNN model with the parameter `metric=\"euclidean\"`. If you are using Manhattan distance, initialize using `metric=\"cityblock\"`.\n",
    "\n",
    "Check the classification accuracy on the development set. It should be very close your performance. If the accuracy is off by more than 5%-points, something might be wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43333333333333335\n",
      "difference bwteen self-built knn and knn in sklearn is: 0.01\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "classifier = sklearn.neighbors.KNeighborsClassifier(n_neighbors=20,weights=\"uniform\", metric=\"euclidean\")\n",
    "classifier.fit(train_X, train_y)\n",
    "\n",
    "sys_dev_y = classifier.predict(dev_X)\n",
    "\n",
    "skl_knn_accuracy = sklearn.metrics.accuracy_score(dev_y, sys_dev_y)\n",
    "print(skl_knn_accuracy)\n",
    "print(\"difference bwteen self-built knn and knn in sklearn is:\", round(skl_knn_accuracy-accuracy_k_dist_func[0][0],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation (10 points)\n",
    "\n",
    "Print the classification report both for your development data and your test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Classification report for development data -----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.15      0.20        13\n",
      "           1       0.50      0.57      0.53        14\n",
      "           2       0.23      0.11      0.15        27\n",
      "           3       0.50      0.43      0.46        21\n",
      "           4       0.00      0.00      0.00         9\n",
      "           5       0.47      0.86      0.61        22\n",
      "           6       0.28      0.41      0.33        17\n",
      "           7       0.39      0.53      0.45        30\n",
      "           8       0.36      0.52      0.43        23\n",
      "           9       0.41      0.39      0.40        33\n",
      "          10       0.77      0.71      0.74        38\n",
      "          11       0.33      0.37      0.35        19\n",
      "          13       0.00      0.00      0.00         5\n",
      "          14       0.37      0.24      0.29        29\n",
      "\n",
      "    accuracy                           0.43       300\n",
      "   macro avg       0.35      0.38      0.35       300\n",
      "weighted avg       0.41      0.43      0.41       300\n",
      "\n",
      "----------- Classification report for test data -----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AA       0.22      0.17      0.19        29\n",
      "          AE       0.21      0.24      0.23        38\n",
      "          AH       0.19      0.13      0.16        54\n",
      "          AO       0.60      0.60      0.60        52\n",
      "          AW       0.25      0.05      0.08        20\n",
      "          AY       0.35      0.75      0.48        40\n",
      "          EH       0.39      0.40      0.40        52\n",
      "          ER       0.43      0.50      0.46        80\n",
      "          EY       0.24      0.40      0.30        42\n",
      "          IH       0.30      0.24      0.27        88\n",
      "          IY       0.75      0.77      0.76        90\n",
      "          OW       0.40      0.34      0.37        56\n",
      "          OY       0.00      0.00      0.00         4\n",
      "          UH       0.00      0.00      0.00         7\n",
      "          UW       0.52      0.33      0.41        48\n",
      "\n",
      "    accuracy                           0.41       700\n",
      "   macro avg       0.32      0.33      0.31       700\n",
      "weighted avg       0.40      0.41      0.39       700\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# report for development data\n",
    "print(\"----------- Classification report for development data -----------\")\n",
    "print(sklearn.metrics.classification_report(dev_y, sys_dev_y))\n",
    "# report for test data\n",
    "sys_test_y = classifier.predict(test_X)\n",
    "print(\"----------- Classification report for test data -----------\")\n",
    "print(sklearn.metrics.classification_report(test_y, sys_test_y, target_names = label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a short report (half a page) of what you did in this assignment. Please also include an analysis of the classification reports. \n",
    "\n",
    "* Do the overall accuracy and f-score agree in the development and test data? \n",
    "* Are some of the classes particularly easy/hard to classify? Why do you think that might be?\n",
    "* Are there any classes which behave differently in the development and test set? \n",
    "* If there are, why do you think they behave differently?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "## Assignment summary\n",
    "### Overview and workflow\n",
    "This assignment aimed to build a knn classifier from scratch to classify vowels based on the first and second formant values (F1 and F2). Performance of my knn classifier was then compared to the knn classifier from the sklearn package. \n",
    "In this assignment, I completed the following tasks.\n",
    "1. Loaded train and test data in .pkl format and stored data in train (2804 examples) and test (700 examples).\n",
    "2. Splited the train data in to train dataset (2504 examples) and development dataset (300 examples).\n",
    "3. Got input (F1 and F2) and output (vowel in integer classes) values for train, dev, and test dataset.\n",
    "4. Defined two distance calculation function, euclidean and manhattan.\n",
    "5. Got the majority baseline by referring to the most frequent vowel class.\n",
    "6. Built a knn classifier. This was done by calculating the distance (euclidean or manhattan) from one data point to all other points in the train dataset, and then assigned the majority class of the k nearest data points as the predicted class. This process was applied to all data points to the dev dataset.\n",
    "7. Ran the knn classifier with different k and distance calculation methods to get the best performance. \n",
    "8. Run knn classifier from the sklearn package with the best k and distance calculation function and compared with my knn performance.\n",
    "### Discussion\n",
    "* The overall accuracy and f-score agree in the development and test dataset. The accuracy and macro and micro average f1-score in the development dataset is slightly higher than those in the test dataset. Possibly beacuse the test dataset contains more data points which might have induce more variability\n",
    "* Based on the classification report for both development and test dataset, it seems the vowel IY has high precision score. It possibly because that IY is a tensed high front vowel that was produced with very small variation and is not overlapped with over vowels in the vowel space. The UH has harder to classify. I inspected the examples for UH and UW and I noticed that a lot of UH was mislabeled as UW (e.g. vowel in to should be UH but labeled as UW), which resulted in high variability in the UW formants.\n",
    "* Classifier performance for the AE vowel varied a lot between development and test set. \n",
    "* I calculate the standard derivation of F1 and F2 of this vowel in the development and test set, and I noticed that std in F2 is larger in the test set (257) than the development set (103). This indicate more variablity in the test set, which might results in more AE being misclassified as another adjacent vowel by the knn classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_formants(data, vowel):\n",
    "    f1 = []\n",
    "    f2 = []\n",
    "    for ex in data:\n",
    "        if ex[\"vowel\"] == vowel:\n",
    "            f1.append(ex[\"F1\"])\n",
    "            f2.append(ex[\"F2\"])\n",
    "    return f1, f2\n",
    "\n",
    "train_f1, train_f2 = get_formants(train, \"AE\")\n",
    "dev_f1, dev_f2 = get_formants(dev, \"AE\")\n",
    "test_f1, test_f2 = get_formants(test, \"AE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     123.000000\n",
       "mean     1794.457724\n",
       "std       313.799404\n",
       "min      1245.900000\n",
       "25%      1584.550000\n",
       "50%      1702.100000\n",
       "75%      1984.400000\n",
       "max      2959.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "f1 = pd.Series(train_f2)\n",
    "f1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      14.000000\n",
       "mean     1551.178571\n",
       "std       103.143374\n",
       "min      1374.500000\n",
       "25%      1501.250000\n",
       "50%      1523.550000\n",
       "75%      1635.800000\n",
       "max      1751.500000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = pd.Series(dev_f2)\n",
    "f1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      38.000000\n",
       "mean     1697.260526\n",
       "std       257.298670\n",
       "min      1315.800000\n",
       "25%      1522.100000\n",
       "50%      1595.100000\n",
       "75%      1860.000000\n",
       "max      2344.600000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = pd.Series(test_f2)\n",
    "f1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
